---
layout: post
date: 2022-09-28 15:59:00-0400
inline: true
---

I'm happy to announce that five papers from our group were accepted to NeurIPS 2022, all related to computer vision and vision–language research. Huge thanks and congratulations to all collaborators!

Accepted papers:

1. GLIPv2: Unifying Localization and VL Understanding — <a href="https://arxiv.org/abs/2206.05836">arXiv:2206.05836</a>
2. Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone — <a href="https://arxiv.org/abs/2206.07643">arXiv:2206.07643</a>
3. K-LITE: Learning Transferable Visual Models with External Knowledge — <a href="https://arxiv.org/abs/2204.09222">arXiv:2204.09222</a>
4. 3DB: A Framework for Debugging Computer Vision Models — <a href="https://arxiv.org/abs/2106.03805">arXiv:2106.03805</a>
5. ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models — <a href="https://arxiv.org/abs/2204.08790">arXiv:2204.08790</a>

We are also organizing an ECCV 2022 workshop, "Computer Vision in the Wild" — see the workshop site: <a href="https://computer-vision-in-the-wild.github.io/eccv-2022/">Computer Vision in the Wild — ECCV 2022</a>.

Last call for papers and challenge participation on topics including open-set recognition and task-level visual transfer.
